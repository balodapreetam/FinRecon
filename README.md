# ğŸ’³ Bank Transaction Reconciliation System

A real-time data pipeline to identify and store **mismatched bank transactions** from two sourcesâ€”Gateway and Ledgerâ€”using **Apache Kafka**, **Apache Spark Structured Streaming**, and **Snowflake**.

---

## ğŸš€ Project Overview

This project simulates a financial reconciliation system where two Kafka producers emit bank transactions from `gateway` and `ledger`. Spark consumes, processes, and compares these streams, then writes any mismatches (e.g., missing in one source) into a Snowflake data warehouse for auditing and analytics.

---

## ğŸ› ï¸ Tech Stack

| Layer              | Tools Used                               |
|--------------------|-------------------------------------------|
| **Programming**     | Python                                   |
| **Streaming Engine**| Apache Spark Structured Streaming        |
| **Message Broker**  | Apache Kafka                             |
| **Data Warehouse**  | Snowflake                                | |

---

## âš™ï¸ Key Features

- ğŸ”„ **Kafka Producers** for Gateway and Ledger streams
- ğŸ” **Full Outer Join** to detect mismatches
- ğŸ§¼ **Stream Cleaning** using `coalesce` and status flags
- â„ï¸ **Snowflake Sink** using `foreachBatch`
- ğŸ’¾ **Checkpointing** for fault tolerance

---

## ğŸ“‚ Project Structure

bash
â”œâ”€â”€ gateway_producer.py       # Sends simulated Gateway transactions to Kafka
â”œâ”€â”€ ledger_producer.py        # Sends simulated Ledger transactions to Kafka
â”œâ”€â”€ consumer_spark.py         # Spark Structured Streaming job to process & write to Snowflake
â””â”€â”€ README.md                 # Project documentation

___



